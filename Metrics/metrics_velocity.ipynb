{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1070c5bc",
   "metadata": {},
   "source": [
    "# Velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7320b73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1022f1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "CSV_PATH = \"/Users/marlenerueschoff/Documents/Uni/UzK Master/Masterarbeit/Experiment/masterthesis_experiment/Data/mouse_events_rows (1).csv\" \n",
    "df_mouse = pd.read_csv(CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "327f6f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         participant_id  total_distance_px  max_speed_px_s  \\\n",
      "0  03dd908a-1650-408d-85b7-1c3403451336       43682.859652    8.220487e+05   \n",
      "1  389c538b-aad3-4787-8030-9adc552993ba       89481.979903    1.018440e+06   \n",
      "2  4aa053ae-bb0b-402a-904a-df94b514460c      161745.269043    1.023145e+06   \n",
      "3  53d7dc68-c8ed-4348-bf2c-5d14cd2cae71        2563.422756    8.520669e+03   \n",
      "4  5bf4b1db-be05-4519-96e7-f4db6467f02a        4633.916208    9.618992e+03   \n",
      "\n",
      "   min_speed_px_s  mean_speed_px_s  std_speed_px_s  mean_abs_dx  mean_abs_dy  \\\n",
      "0             0.0    143894.529416   243842.619798   182.870056   146.423729   \n",
      "1             0.0     80500.238250   182951.358954    97.983752    72.534712   \n",
      "2             0.0    114460.415493   203979.815220   245.568182    61.849026   \n",
      "3             0.0       817.631061     1970.874908    28.101266    11.291139   \n",
      "4             0.0       419.467083     1030.996727    11.228261     9.456522   \n",
      "\n",
      "   n_steps  \n",
      "0      177  \n",
      "1      677  \n",
      "2      616  \n",
      "3       79  \n",
      "4      276  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v_/5q_t13ds7pz7yhp0h3fhnrr40000gn/T/ipykernel_21535/1863991554.py:40: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(_deltas)\n"
     ]
    }
   ],
   "source": [
    "GROUPING = (\"participant_id\",)\n",
    "\n",
    "def compute_velocity_from_df(df_mouse: pd.DataFrame,\n",
    "                             group_cols=GROUPING) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    required = {\"participant_id\", \"t_ms\", \"x\", \"y\"}\n",
    "    missing = required - set(df_mouse.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"df_mouse is missing required columns: {missing}\")\n",
    "\n",
    "    # Work on a copy to avoid side-effects (set copy=False if you want in-place)\n",
    "    df = df_mouse.copy()\n",
    "\n",
    "    # Ensure numeric types\n",
    "    df[\"t_ms\"] = pd.to_numeric(df[\"t_ms\"], errors=\"coerce\")\n",
    "    df[\"x\"]    = pd.to_numeric(df[\"x\"], errors=\"coerce\")\n",
    "    df[\"y\"]    = pd.to_numeric(df[\"y\"], errors=\"coerce\")\n",
    "\n",
    "    # Drop unusable rows\n",
    "    df = df.dropna(subset=[\"participant_id\", \"t_ms\", \"x\", \"y\"])\n",
    "\n",
    "    # Sort within groups by time\n",
    "    sort_cols = list(group_cols) + [\"t_ms\"]\n",
    "    df = df.sort_values(sort_cols)\n",
    "\n",
    "    # Compute deltas per group\n",
    "    def _deltas(g: pd.DataFrame) -> pd.DataFrame:\n",
    "        g = g.copy()\n",
    "        g[\"dx\"] = g[\"x\"].diff()\n",
    "        g[\"dy\"] = g[\"y\"].diff()\n",
    "        g[\"dt_ms\"] = g[\"t_ms\"].diff()\n",
    "        g[\"dist_px\"] = np.sqrt(g[\"dx\"]**2 + g[\"dy\"]**2)\n",
    "        g[\"dt_s\"] = g[\"dt_ms\"] / 1000.0\n",
    "        # guard against zero/negative/NaN intervals\n",
    "        g.loc[~np.isfinite(g[\"dt_s\"]) | (g[\"dt_s\"] <= 0), [\"dt_s\", \"dist_px\", \"dx\", \"dy\"]] = np.nan\n",
    "        g[\"speed_px_s\"] = g[\"dist_px\"] / g[\"dt_s\"]\n",
    "        return g\n",
    "\n",
    "    df_steps = (\n",
    "        df.groupby(list(group_cols), dropna=False, as_index=False, group_keys=False)\n",
    "          .apply(_deltas)\n",
    "    )\n",
    "\n",
    "    # Keep only valid step rows for aggregation (the first in each group will be NaN)\n",
    "    valid = df_steps.dropna(subset=[\"dist_px\", \"dt_s\", \"speed_px_s\"]).copy()\n",
    "\n",
    "    if valid.empty:\n",
    "        # Return empty results with expected columns if nothing to compute\n",
    "        empty_cols = list(group_cols) + [\n",
    "            \"total_distance_px\",\"max_speed_px_s\",\"min_speed_px_s\",\n",
    "            \"mean_speed_px_s\",\"std_speed_px_s\",\"mean_abs_dx\",\"mean_abs_dy\",\"n_steps\"\n",
    "        ]\n",
    "        metrics = pd.DataFrame(columns=empty_cols)\n",
    "        return metrics, df_steps\n",
    "\n",
    "    grouped = valid.groupby(list(group_cols), dropna=False)\n",
    "\n",
    "    metrics = grouped.agg(\n",
    "        total_distance_px = (\"dist_px\", \"sum\"),\n",
    "        max_speed_px_s    = (\"speed_px_s\", \"max\"),\n",
    "        min_speed_px_s    = (\"speed_px_s\", \"min\"),\n",
    "        mean_speed_px_s   = (\"speed_px_s\", \"mean\"),\n",
    "        std_speed_px_s    = (\"speed_px_s\", \"std\"),\n",
    "        mean_abs_dx       = (\"dx\",  lambda s: np.nanmean(np.abs(s))),\n",
    "        mean_abs_dy       = (\"dy\",  lambda s: np.nanmean(np.abs(s))),\n",
    "        n_steps           = (\"speed_px_s\", \"count\"),\n",
    "    ).reset_index()\n",
    "\n",
    "    # For groups with only one valid step, std is NaN → set to 0.0\n",
    "    metrics[\"std_speed_px_s\"] = metrics[\"std_speed_px_s\"].fillna(0.0)\n",
    "\n",
    "    return metrics, df_steps\n",
    "\n",
    "# ---- Use it on your existing df_mouse ----\n",
    "metrics, df_mouse_with_steps = compute_velocity_from_df(df_mouse, group_cols=GROUPING)\n",
    "\n",
    "# Peek at results\n",
    "print(metrics.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18ab516",
   "metadata": {},
   "source": [
    "# Submovements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1644dc6",
   "metadata": {},
   "source": [
    "Hyperparameters\n",
    "ROLL_WIN_SAMPLES = Size of the centered moving average applied to the speed series before finding peaks \n",
    "-> Typical: 3–5 (with ~40 ms sampling, that’s ~120–200 ms smoothing).\n",
    "-> Effect:\n",
    "    Larger → smoother curve, fewer peaks.\n",
    "    Smaller → noisier curve, more peaks.\n",
    "\n",
    "MIN_PROMINENCE_PX_S = How much higher a peak must be relative to its immediate left/right valleys.\n",
    "-> Start around the 20th–40th percentile of non-zero speeds.\n",
    "-> Effect:\n",
    "    Larger → suppresses small/flat bumps → fewer, more salient peaks.\n",
    "    Smaller → allows small bumps → more peaks, including noise.\n",
    "\n",
    "MIN_PEAK_HEIGHT_PX_S = absolute minimum peak height, px/s\n",
    "-> Typical: Just above your noise floor, e.g., median(speed when moving slowly) or P10–P20 of all positive speeds.\n",
    "-> Effect:\n",
    "    Larger → discards slow, possibly jitter-based peaks.\n",
    "    Smaller → admits slow “peaks” → risk of false positives during tiny moves.\n",
    "\n",
    "MIN_PEAK_DISTANCE_MS = Minimum elapsed time between accepted peaks\n",
    "-> Typical: 200 ms (aligns with your pause notion); range 120–300 ms.\n",
    "-> Effect:\n",
    "    Larger → merges nearby peaks → fewer but longer submovements.\n",
    "    Smaller → allows rapid successive peaks → more submovements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050fb77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-trial (first 10 rows):\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'agg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 135\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m per_trial, agg\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-trial (first 10 rows):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 135\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43magg\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'agg' is not defined"
     ]
    }
   ],
   "source": [
    "# Peak detection hyperparams\n",
    "ROLL_WIN_SAMPLES      = 3      # ~120 ms if ~40 ms sampling / no changes \n",
    "MIN_PROMINENCE_PX_S   = 50.0   # tune on your data / no changes\n",
    "MIN_PEAK_HEIGHT_PX_S  = 50.0   # tune on your data\n",
    "MIN_PEAK_DISTANCE_MS  = 200    # refractory period\n",
    "\n",
    "# ============================\n",
    "# Helpers\n",
    "# ============================\n",
    "\n",
    "def _moving_avg(a, win):\n",
    "    if win <= 1:\n",
    "        return a\n",
    "    return pd.Series(a, dtype=\"float64\").rolling(win, center=True, min_periods=1).mean().to_numpy()\n",
    "\n",
    "def _compute_speed_px_s_aligned(g: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute speed (px/s) aligned to g.index.\n",
    "    First sample is NaN; rows where dt<=0 are NaN (prevents divide-by-zero warnings).\n",
    "    \"\"\"\n",
    "    dx   = g[\"x\"].diff().to_numpy(dtype=\"float64\")\n",
    "    dy   = g[\"y\"].diff().to_numpy(dtype=\"float64\")\n",
    "    dt_s = (g[\"t_ms\"].diff() / 1000.0).to_numpy(dtype=\"float64\")\n",
    "\n",
    "    # distances\n",
    "    dist = np.sqrt(dx*dx + dy*dy)\n",
    "\n",
    "    # mask invalid dt_s BEFORE division\n",
    "    invalid = ~np.isfinite(dt_s) | (dt_s <= 0)\n",
    "    v = np.empty_like(dt_s, dtype=\"float64\")\n",
    "    v[:] = np.nan\n",
    "    ok = ~invalid\n",
    "    v[ok] = dist[ok] / dt_s[ok]  # px/s\n",
    "\n",
    "    # first row stays NaN\n",
    "    return v\n",
    "\n",
    "def _find_speed_peaks(v_smooth, t_ms, min_prominence, min_height, min_peak_distance_ms):\n",
    "    peaks = []\n",
    "    n = len(v_smooth)\n",
    "    last_peak_time = -np.inf\n",
    "\n",
    "    for i in range(1, n-1):\n",
    "        vi = v_smooth[i]\n",
    "        if not np.isfinite(vi):\n",
    "            continue\n",
    "        if vi <= (v_smooth[i-1] if np.isfinite(v_smooth[i-1]) else -np.inf):\n",
    "            continue\n",
    "        if vi <= (v_smooth[i+1] if np.isfinite(v_smooth[i+1]) else -np.inf):\n",
    "            continue\n",
    "        if vi < min_height:\n",
    "            continue\n",
    "        left  = v_smooth[i-1] if np.isfinite(v_smooth[i-1]) else -np.inf\n",
    "        right = v_smooth[i+1] if np.isfinite(v_smooth[i+1]) else -np.inf\n",
    "        prom = vi - max(left, right)\n",
    "        if prom < min_prominence:\n",
    "            continue\n",
    "        if (t_ms[i] - last_peak_time) < min_peak_distance_ms:\n",
    "            continue\n",
    "        peaks.append(i)\n",
    "        last_peak_time = t_ms[i]\n",
    "    return np.array(peaks, dtype=int)\n",
    "\n",
    "def _count_submovements_speed_peaks(g,\n",
    "                                    roll_win=ROLL_WIN_SAMPLES,\n",
    "                                    min_prom=MIN_PROMINENCE_PX_S,\n",
    "                                    min_height=MIN_PEAK_HEIGHT_PX_S,\n",
    "                                    min_dist_ms=MIN_PEAK_DISTANCE_MS):\n",
    "    g = g.sort_values(\"t_ms\").reset_index(drop=True)\n",
    "\n",
    "    # ensure numeric\n",
    "    g[\"t_ms\"] = pd.to_numeric(g[\"t_ms\"], errors=\"coerce\")\n",
    "    g[\"x\"]    = pd.to_numeric(g[\"x\"], errors=\"coerce\")\n",
    "    g[\"y\"]    = pd.to_numeric(g[\"y\"], errors=\"coerce\")\n",
    "    g = g.dropna(subset=[\"t_ms\", \"x\", \"y\"])\n",
    "\n",
    "    if len(g) < 3:\n",
    "        dur = float(g[\"t_ms\"].iloc[-1] - g[\"t_ms\"].iloc[0]) if len(g) else np.nan\n",
    "        rate = (0 / (dur/1000.0)) if (np.isfinite(dur) and dur > 0) else np.nan\n",
    "        return pd.DataFrame({\"submovements\":[0], \"trial_duration_ms\":[dur], \"submovements_per_s\":[rate]})\n",
    "\n",
    "    # Reuse existing speed if present; otherwise compute robustly\n",
    "    if \"speed_px_s\" in g.columns and g[\"speed_px_s\"].notna().any():\n",
    "        v = g[\"speed_px_s\"].to_numpy(dtype=\"float64\")\n",
    "        # Mask pathological values from earlier steps\n",
    "        v[~np.isfinite(v)] = np.nan\n",
    "    else:\n",
    "        v = _compute_speed_px_s_aligned(g)\n",
    "\n",
    "    t_ms = g[\"t_ms\"].to_numpy(dtype=\"float64\")\n",
    "    v_s  = _moving_avg(v, roll_win)\n",
    "    peaks = _find_speed_peaks(v_s, t_ms,\n",
    "                              min_prominence=min_prom,\n",
    "                              min_height=min_height,\n",
    "                              min_peak_distance_ms=min_dist_ms)\n",
    "    submoves = int(peaks.size)\n",
    "    dur = float(t_ms[-1] - t_ms[0])\n",
    "    rate = submoves / (dur/1000.0) if (np.isfinite(dur) and dur > 0) else np.nan\n",
    "\n",
    "    return pd.DataFrame({\"submovements\":[submoves],\n",
    "                         \"trial_duration_ms\":[dur],\n",
    "                         \"submovements_per_s\":[rate]})\n",
    "\n",
    "def submovements_per_trial_speed_peaks(df_mouse, group_cols=GROUPING):\n",
    "    needed = set(group_cols) | {\"t_ms\", \"x\", \"y\"}\n",
    "    missing = [c for c in needed if c not in df_mouse.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"df_mouse is missing required columns: {missing}\")\n",
    "\n",
    "    gobj = df_mouse.groupby(list(group_cols), dropna=False, group_keys=False)\n",
    "\n",
    "    # Use include_groups=False when available (pandas >= 2.2); otherwise fallback\n",
    "    try:\n",
    "        out = gobj.apply(lambda g: _count_submovements_speed_peaks(g), include_groups=False)\n",
    "    except TypeError:\n",
    "        out = gobj.apply(lambda g: _count_submovements_speed_peaks(g))\n",
    "    out = out.reset_index()\n",
    "    # Clean accidental 'level_*' columns if any\n",
    "    out = out.drop(columns=[c for c in out.columns if c.startswith(\"level_\")], errors=\"ignore\")\n",
    "    return out\n",
    "\n",
    "def submovements_per_participant_speed_peaks(df_mouse, group_cols=GROUPING):\n",
    "    per_trial = submovements_per_trial_speed_peaks(df_mouse, group_cols=group_cols)\n",
    "    part_col = \"participant_id\" if \"participant_id\" in group_cols else group_cols[0]\n",
    "\n",
    "    agg = (per_trial.groupby(part_col, as_index=False)\n",
    "                  .agg(total_submovements=(\"submovements\", \"sum\"),\n",
    "                       total_trial_time_ms=(\"trial_duration_ms\", \"sum\")))\n",
    "    agg[\"submovements_per_s\"] = agg[\"total_submovements\"] / (agg[\"total_trial_time_ms\"] / 1000.0)\n",
    "    return per_trial, agg\n",
    "\n",
    "\n",
    "\n",
    "print(\"Per-trial (first 10 rows):\")\n",
    "print(per_trial.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e938581",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
