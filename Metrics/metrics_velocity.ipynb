{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1070c5bc",
   "metadata": {},
   "source": [
    "# Velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7320b73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1022f1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "CSV_PATH = \"/Users/marlenerueschoff/Documents/Uni/UzK Master/Masterarbeit/Experiment/masterthesis_experiment/Data/mouse_events_rows (1).csv\" \n",
    "df_mouse = pd.read_csv(CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "327f6f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         participant_id  total_distance_px  max_speed_px_s  \\\n",
      "0  03dd908a-1650-408d-85b7-1c3403451336       43682.859652    8.220487e+05   \n",
      "1  389c538b-aad3-4787-8030-9adc552993ba       89481.979903    1.018440e+06   \n",
      "2  4aa053ae-bb0b-402a-904a-df94b514460c      161745.269043    1.023145e+06   \n",
      "3  53d7dc68-c8ed-4348-bf2c-5d14cd2cae71        2563.422756    8.520669e+03   \n",
      "4  5bf4b1db-be05-4519-96e7-f4db6467f02a        4633.916208    9.618992e+03   \n",
      "\n",
      "   min_speed_px_s  mean_speed_px_s  std_speed_px_s  mean_abs_dx  mean_abs_dy  \\\n",
      "0             0.0    143894.529416   243842.619798   182.870056   146.423729   \n",
      "1             0.0     80500.238250   182951.358954    97.983752    72.534712   \n",
      "2             0.0    114460.415493   203979.815220   245.568182    61.849026   \n",
      "3             0.0       817.631061     1970.874908    28.101266    11.291139   \n",
      "4             0.0       419.467083     1030.996727    11.228261     9.456522   \n",
      "\n",
      "   n_steps  \n",
      "0      177  \n",
      "1      677  \n",
      "2      616  \n",
      "3       79  \n",
      "4      276  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v_/5q_t13ds7pz7yhp0h3fhnrr40000gn/T/ipykernel_38998/1863991554.py:40: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(_deltas)\n"
     ]
    }
   ],
   "source": [
    "GROUPING = (\"participant_id\",)\n",
    "\n",
    "def compute_velocity_from_df(df_mouse: pd.DataFrame,\n",
    "                             group_cols=GROUPING) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    required = {\"participant_id\", \"t_ms\", \"x\", \"y\"}\n",
    "    missing = required - set(df_mouse.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"df_mouse is missing required columns: {missing}\")\n",
    "\n",
    "    # Work on a copy to avoid side-effects (set copy=False if you want in-place)\n",
    "    df = df_mouse.copy()\n",
    "\n",
    "    # Ensure numeric types\n",
    "    df[\"t_ms\"] = pd.to_numeric(df[\"t_ms\"], errors=\"coerce\")\n",
    "    df[\"x\"]    = pd.to_numeric(df[\"x\"], errors=\"coerce\")\n",
    "    df[\"y\"]    = pd.to_numeric(df[\"y\"], errors=\"coerce\")\n",
    "\n",
    "    # Drop unusable rows\n",
    "    df = df.dropna(subset=[\"participant_id\", \"t_ms\", \"x\", \"y\"])\n",
    "\n",
    "    # Sort within groups by time\n",
    "    sort_cols = list(group_cols) + [\"t_ms\"]\n",
    "    df = df.sort_values(sort_cols)\n",
    "\n",
    "    # Compute deltas per group\n",
    "    def _deltas(g: pd.DataFrame) -> pd.DataFrame:\n",
    "        g = g.copy()\n",
    "        g[\"dx\"] = g[\"x\"].diff()\n",
    "        g[\"dy\"] = g[\"y\"].diff()\n",
    "        g[\"dt_ms\"] = g[\"t_ms\"].diff()\n",
    "        g[\"dist_px\"] = np.sqrt(g[\"dx\"]**2 + g[\"dy\"]**2)\n",
    "        g[\"dt_s\"] = g[\"dt_ms\"] / 1000.0\n",
    "        # guard against zero/negative/NaN intervals\n",
    "        g.loc[~np.isfinite(g[\"dt_s\"]) | (g[\"dt_s\"] <= 0), [\"dt_s\", \"dist_px\", \"dx\", \"dy\"]] = np.nan\n",
    "        g[\"speed_px_s\"] = g[\"dist_px\"] / g[\"dt_s\"]\n",
    "        return g\n",
    "\n",
    "    df_steps = (\n",
    "        df.groupby(list(group_cols), dropna=False, as_index=False, group_keys=False)\n",
    "          .apply(_deltas)\n",
    "    )\n",
    "\n",
    "    # Keep only valid step rows for aggregation (the first in each group will be NaN)\n",
    "    valid = df_steps.dropna(subset=[\"dist_px\", \"dt_s\", \"speed_px_s\"]).copy()\n",
    "\n",
    "    if valid.empty:\n",
    "        # Return empty results with expected columns if nothing to compute\n",
    "        empty_cols = list(group_cols) + [\n",
    "            \"total_distance_px\",\"max_speed_px_s\",\"min_speed_px_s\",\n",
    "            \"mean_speed_px_s\",\"std_speed_px_s\",\"mean_abs_dx\",\"mean_abs_dy\",\"n_steps\"\n",
    "        ]\n",
    "        metrics = pd.DataFrame(columns=empty_cols)\n",
    "        return metrics, df_steps\n",
    "\n",
    "    grouped = valid.groupby(list(group_cols), dropna=False)\n",
    "\n",
    "    metrics = grouped.agg(\n",
    "        total_distance_px = (\"dist_px\", \"sum\"),\n",
    "        max_speed_px_s    = (\"speed_px_s\", \"max\"),\n",
    "        min_speed_px_s    = (\"speed_px_s\", \"min\"),\n",
    "        mean_speed_px_s   = (\"speed_px_s\", \"mean\"),\n",
    "        std_speed_px_s    = (\"speed_px_s\", \"std\"),\n",
    "        mean_abs_dx       = (\"dx\",  lambda s: np.nanmean(np.abs(s))),\n",
    "        mean_abs_dy       = (\"dy\",  lambda s: np.nanmean(np.abs(s))),\n",
    "        n_steps           = (\"speed_px_s\", \"count\"),\n",
    "    ).reset_index()\n",
    "\n",
    "    # For groups with only one valid step, std is NaN → set to 0.0\n",
    "    metrics[\"std_speed_px_s\"] = metrics[\"std_speed_px_s\"].fillna(0.0)\n",
    "\n",
    "    return metrics, df_steps\n",
    "\n",
    "# ---- Use it on your existing df_mouse ----\n",
    "metrics, df_mouse_with_steps = compute_velocity_from_df(df_mouse, group_cols=GROUPING)\n",
    "\n",
    "# Peek at results\n",
    "print(metrics.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18ab516",
   "metadata": {},
   "source": [
    "# Submovements + Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1644dc6",
   "metadata": {},
   "source": [
    "Hyperparameters\n",
    "ROLL_WIN_SAMPLES = Size of the centered moving average applied to the speed series before finding peaks \n",
    "-> Typical: 3–5 (with ~40 ms sampling, that’s ~120–200 ms smoothing).\n",
    "-> Effect:\n",
    "    Larger → smoother curve, fewer peaks.\n",
    "    Smaller → noisier curve, more peaks.\n",
    "\n",
    "MIN_PROMINENCE_PX_S = How much higher a peak must be relative to its immediate left/right valleys.\n",
    "-> Start around the 20th–40th percentile of non-zero speeds.\n",
    "-> Effect:\n",
    "    Larger → suppresses small/flat bumps → fewer, more salient peaks.\n",
    "    Smaller → allows small bumps → more peaks, including noise.\n",
    "\n",
    "MIN_PEAK_HEIGHT_PX_S = absolute minimum peak height, px/s\n",
    "-> Typical: Just above your noise floor, e.g., median(speed when moving slowly) or P10–P20 of all positive speeds.\n",
    "-> Effect:\n",
    "    Larger → discards slow, possibly jitter-based peaks.\n",
    "    Smaller → admits slow “peaks” → risk of false positives during tiny moves.\n",
    "\n",
    "MIN_PEAK_DISTANCE_MS = Minimum elapsed time between accepted peaks\n",
    "-> Typical: 200 ms (aligns with your pause notion); range 120–300 ms.\n",
    "-> Effect:\n",
    "    Larger → merges nearby peaks → fewer but longer submovements.\n",
    "    Smaller → allows rapid successive peaks → more submovements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "050fb77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-trial (first 10 rows):\n",
      "                         participant_id  submovements  trial_duration_ms  \\\n",
      "0  03dd908a-1650-408d-85b7-1c3403451336            11             3931.0   \n",
      "1  389c538b-aad3-4787-8030-9adc552993ba            23            20430.0   \n",
      "2  4aa053ae-bb0b-402a-904a-df94b514460c            47            33607.0   \n",
      "3  53d7dc68-c8ed-4348-bf2c-5d14cd2cae71             3             3228.0   \n",
      "4  5bf4b1db-be05-4519-96e7-f4db6467f02a             9            11147.0   \n",
      "5  5cb2ad99-b1e4-4f9e-b88f-24cb9369f149           370          4603988.0   \n",
      "6  6b2a8aac-5a24-4ad4-a558-1e8831eed188             3            10131.0   \n",
      "7  7da173ae-4330-4b89-9b5c-acefbdef1966             2             3854.0   \n",
      "8  81aeb982-e2d1-443c-9379-2fc3bb91ca7f            16           101028.0   \n",
      "9  873da617-fe45-44c3-96ca-5cc36cb89eae            10            13644.0   \n",
      "\n",
      "   submovements_per_s  mean_submovement_deviation  \n",
      "0            2.798270                   19.124213  \n",
      "1            1.125795                   43.163420  \n",
      "2            1.398518                   72.964782  \n",
      "3            0.929368                    1.239464  \n",
      "4            0.807392                    1.364762  \n",
      "5            0.080365                   66.636790  \n",
      "6            0.296121                    1.233827  \n",
      "7            0.518941                    1.530983  \n",
      "8            0.158372                  231.786024  \n",
      "9            0.732923                   12.526671  \n",
      "\n",
      "Per-participant (first 10 rows):\n",
      "                         participant_id  total_submovements  \\\n",
      "0  03dd908a-1650-408d-85b7-1c3403451336                  11   \n",
      "1  389c538b-aad3-4787-8030-9adc552993ba                  23   \n",
      "2  4aa053ae-bb0b-402a-904a-df94b514460c                  47   \n",
      "3  53d7dc68-c8ed-4348-bf2c-5d14cd2cae71                   3   \n",
      "4  5bf4b1db-be05-4519-96e7-f4db6467f02a                   9   \n",
      "5  5cb2ad99-b1e4-4f9e-b88f-24cb9369f149                 370   \n",
      "6  6b2a8aac-5a24-4ad4-a558-1e8831eed188                   3   \n",
      "7  7da173ae-4330-4b89-9b5c-acefbdef1966                   2   \n",
      "8  81aeb982-e2d1-443c-9379-2fc3bb91ca7f                  16   \n",
      "9  873da617-fe45-44c3-96ca-5cc36cb89eae                  10   \n",
      "\n",
      "   total_trial_time_ms  mean_dev_over_trials  submovements_per_s  \n",
      "0               3931.0             19.124213            2.798270  \n",
      "1              20430.0             43.163420            1.125795  \n",
      "2              33607.0             72.964782            1.398518  \n",
      "3               3228.0              1.239464            0.929368  \n",
      "4              11147.0              1.364762            0.807392  \n",
      "5            4603988.0             66.636790            0.080365  \n",
      "6              10131.0              1.233827            0.296121  \n",
      "7               3854.0              1.530983            0.518941  \n",
      "8             101028.0            231.786024            0.158372  \n",
      "9              13644.0             12.526671            0.732923  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v_/5q_t13ds7pz7yhp0h3fhnrr40000gn/T/ipykernel_38998/3353622450.py:359: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = gobj.apply(lambda g: _count_submovements_speed_peaks(g))\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 0) Peak detection hyperparameters\n",
    "# =============================================================================\n",
    "ROLL_WIN_SAMPLES      = 3      # ~120 ms if sampling interval is ~40 ms\n",
    "MIN_PROMINENCE_PX_S   = 50.0   # required prominence of a speed peak (tune on data)\n",
    "MIN_PEAK_HEIGHT_PX_S  = 50.0   # minimum peak speed to count as submovement (px/s)\n",
    "MIN_PEAK_DISTANCE_MS  = 200    # minimum time between two peaks (ms; refractory period)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 1) Helper functions\n",
    "# =============================================================================\n",
    "\n",
    "def _moving_avg(a: np.ndarray, win: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute a simple centered moving average over a 1D array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : np.ndarray\n",
    "        Input array (e.g., speed over time).\n",
    "    win : int\n",
    "        Window length. If win <= 1, the original array is returned.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Smoothed array of the same length as `a`.\n",
    "    \"\"\"\n",
    "    if win <= 1:\n",
    "        return a\n",
    "    return (\n",
    "        pd.Series(a, dtype=\"float64\")\n",
    "        .rolling(win, center=True, min_periods=1)\n",
    "        .mean()\n",
    "        .to_numpy()\n",
    "    )\n",
    "\n",
    "\n",
    "def _compute_speed_px_s_aligned(g: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute pointwise speed (px/s) for a trajectory DataFrame, aligned to g.index.\n",
    "\n",
    "    Uses:\n",
    "    - finite forward differences in x, y\n",
    "    - time differences in milliseconds\n",
    "\n",
    "    Any time differences that are non-finite or <= 0 are treated as invalid,\n",
    "    and the corresponding speed entries are set to NaN.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    g : pd.DataFrame\n",
    "        DataFrame with at least columns 'x', 'y', 't_ms'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Speed in px/s, same length as g, with NaN for the first row\n",
    "        and invalid time steps.\n",
    "    \"\"\"\n",
    "    dx   = g[\"x\"].diff().to_numpy(dtype=\"float64\")\n",
    "    dy   = g[\"y\"].diff().to_numpy(dtype=\"float64\")\n",
    "    dt_s = (g[\"t_ms\"].diff() / 1000.0).to_numpy(dtype=\"float64\")\n",
    "\n",
    "    # Euclidean distance between consecutive samples\n",
    "    dist = np.sqrt(dx * dx + dy * dy)\n",
    "\n",
    "    # Mark invalid time intervals before division\n",
    "    invalid = ~np.isfinite(dt_s) | (dt_s <= 0)\n",
    "\n",
    "    # Pre-allocate speed array\n",
    "    v = np.empty_like(dt_s, dtype=\"float64\")\n",
    "    v[:] = np.nan\n",
    "\n",
    "    ok = ~invalid\n",
    "    v[ok] = dist[ok] / dt_s[ok]  # px/s for valid intervals\n",
    "\n",
    "    # The first row remains NaN (no previous sample)\n",
    "    return v\n",
    "\n",
    "\n",
    "def _find_speed_peaks(\n",
    "    v_smooth: np.ndarray,\n",
    "    t_ms: np.ndarray,\n",
    "    min_prominence: float,\n",
    "    min_height: float,\n",
    "    min_peak_distance_ms: float\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Detect local maxima (speed peaks) in a smoothed speed signal.\n",
    "\n",
    "    A peak is accepted if:\n",
    "    - it is a local maximum compared to its immediate neighbors,\n",
    "    - its value >= min_height,\n",
    "    - its prominence relative to neighbors >= min_prominence,\n",
    "    - it is at least min_peak_distance_ms after the last accepted peak.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    v_smooth : np.ndarray\n",
    "        Smoothed speed (px/s).\n",
    "    t_ms : np.ndarray\n",
    "        Timestamps in milliseconds, same length as v_smooth.\n",
    "    min_prominence : float\n",
    "        Minimum prominence relative to neighbors.\n",
    "    min_height : float\n",
    "        Minimum absolute height of the peak (px/s).\n",
    "    min_peak_distance_ms : float\n",
    "        Minimum time between two accepted peaks in ms.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Array of indices (into v_smooth / original trajectory) where peaks occur.\n",
    "    \"\"\"\n",
    "    peaks = []\n",
    "    n = len(v_smooth)\n",
    "    last_peak_time = -np.inf\n",
    "\n",
    "    for i in range(1, n - 1):\n",
    "        vi = v_smooth[i]\n",
    "        if not np.isfinite(vi):\n",
    "            continue\n",
    "\n",
    "        # Neighbor values (fall back to -inf if NaN)\n",
    "        left_val  = v_smooth[i - 1] if np.isfinite(v_smooth[i - 1]) else -np.inf\n",
    "        right_val = v_smooth[i + 1] if np.isfinite(v_smooth[i + 1]) else -np.inf\n",
    "\n",
    "        # Local maximum check\n",
    "        if vi <= left_val:\n",
    "            continue\n",
    "        if vi <= right_val:\n",
    "            continue\n",
    "\n",
    "        # Minimum height check\n",
    "        if vi < min_height:\n",
    "            continue\n",
    "\n",
    "        # Prominence relative to neighbors\n",
    "        prom = vi - max(left_val, right_val)\n",
    "        if prom < min_prominence:\n",
    "            continue\n",
    "\n",
    "        # Enforce minimum temporal distance between peaks\n",
    "        if (t_ms[i] - last_peak_time) < min_peak_distance_ms:\n",
    "            continue\n",
    "\n",
    "        peaks.append(i)\n",
    "        last_peak_time = t_ms[i]\n",
    "\n",
    "    return np.array(peaks, dtype=int)\n",
    "\n",
    "\n",
    "def _compute_submovement_deviations(g: pd.DataFrame, peaks: np.ndarray) -> list[float]:\n",
    "    \"\"\"\n",
    "    Compute submovement deviations for a set of peaks within one trajectory.\n",
    "\n",
    "    Each submovement is defined as the segment between peak k and peak k+1.\n",
    "    For each segment:\n",
    "        deviation = actual path length / straight-line distance\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    g : pd.DataFrame\n",
    "        DataFrame for a single group/trajectory, with columns 'x', 'y'.\n",
    "    peaks : np.ndarray\n",
    "        Indices of detected speed peaks (into g).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[float]\n",
    "        Deviation values for all submovement segments (may contain NaNs).\n",
    "    \"\"\"\n",
    "    x = g[\"x\"].to_numpy(dtype=\"float64\")\n",
    "    y = g[\"y\"].to_numpy(dtype=\"float64\")\n",
    "\n",
    "    devs: list[float] = []\n",
    "\n",
    "    # Build segments between successive peaks: [peaks[k], peaks[k+1]]\n",
    "    for k in range(len(peaks) - 1):\n",
    "        i0 = peaks[k]\n",
    "        i1 = peaks[k + 1]\n",
    "        if i1 <= i0:\n",
    "            continue\n",
    "\n",
    "        xs = x[i0:i1 + 1]\n",
    "        ys = y[i0:i1 + 1]\n",
    "\n",
    "        # Actual path length\n",
    "        dx = np.diff(xs)\n",
    "        dy = np.diff(ys)\n",
    "        actual_dist = np.sum(np.sqrt(dx * dx + dy * dy))\n",
    "\n",
    "        # Straight-line distance (start to end)\n",
    "        shortest_dist = np.sqrt((xs[-1] - xs[0])**2 + (ys[-1] - ys[0])**2)\n",
    "\n",
    "        if shortest_dist > 0:\n",
    "            devs.append(actual_dist / shortest_dist)\n",
    "        else:\n",
    "            devs.append(np.nan)\n",
    "\n",
    "    return devs\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2) Core per-group computation\n",
    "# =============================================================================\n",
    "\n",
    "def _count_submovements_speed_peaks(\n",
    "    g: pd.DataFrame,\n",
    "    roll_win: int = ROLL_WIN_SAMPLES,\n",
    "    min_prom: float = MIN_PROMINENCE_PX_S,\n",
    "    min_height: float = MIN_PEAK_HEIGHT_PX_S,\n",
    "    min_dist_ms: float = MIN_PEAK_DISTANCE_MS\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute submovement metrics for a single group/trajectory `g` using speed peaks.\n",
    "\n",
    "    Steps:\n",
    "    1. Sort by time and clean numeric columns.\n",
    "    2. Compute or reuse speed ('speed_px_s').\n",
    "    3. Smooth the speed signal.\n",
    "    4. Detect peaks in smoothed speed.\n",
    "    5. Derive:\n",
    "        - number of submovements,\n",
    "        - trial duration,\n",
    "        - submovements per second,\n",
    "        - mean submovement deviation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    g : pd.DataFrame\n",
    "        Single group of mouse data, containing at least 't_ms', 'x', 'y'.\n",
    "        If 'speed_px_s' is present, it will be reused.\n",
    "    roll_win : int\n",
    "        Window length for moving average smoothing.\n",
    "    min_prom : float\n",
    "        Minimum prominence of a peak.\n",
    "    min_height : float\n",
    "        Minimum absolute height of a peak.\n",
    "    min_dist_ms : float\n",
    "        Minimum time between peaks in ms.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        One-row DataFrame with:\n",
    "        - submovements\n",
    "        - trial_duration_ms\n",
    "        - submovements_per_s\n",
    "        - mean_submovement_deviation\n",
    "    \"\"\"\n",
    "    # Ensure sorted by time and numeric types\n",
    "    g = g.sort_values(\"t_ms\").reset_index(drop=True)\n",
    "    g[\"t_ms\"] = pd.to_numeric(g[\"t_ms\"], errors=\"coerce\")\n",
    "    g[\"x\"]    = pd.to_numeric(g[\"x\"],  errors=\"coerce\")\n",
    "    g[\"y\"]    = pd.to_numeric(g[\"y\"],  errors=\"coerce\")\n",
    "    g = g.dropna(subset=[\"t_ms\", \"x\", \"y\"])\n",
    "\n",
    "    # If too few samples, we cannot detect peaks reliably\n",
    "    if len(g) < 3:\n",
    "        if len(g):\n",
    "            dur = float(g[\"t_ms\"].iloc[-1] - g[\"t_ms\"].iloc[0])\n",
    "        else:\n",
    "            dur = np.nan\n",
    "\n",
    "        rate = (0 / (dur / 1000.0)) if (np.isfinite(dur) and dur > 0) else np.nan\n",
    "        return pd.DataFrame(\n",
    "            {\n",
    "                \"submovements\": [0],\n",
    "                \"trial_duration_ms\": [dur],\n",
    "                \"submovements_per_s\": [rate],\n",
    "                \"mean_submovement_deviation\": [np.nan],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Reuse existing speed if present; otherwise compute fresh\n",
    "    if \"speed_px_s\" in g.columns and g[\"speed_px_s\"].notna().any():\n",
    "        v = g[\"speed_px_s\"].to_numpy(dtype=\"float64\")\n",
    "        v[~np.isfinite(v)] = np.nan\n",
    "    else:\n",
    "        v = _compute_speed_px_s_aligned(g)\n",
    "\n",
    "    t_ms = g[\"t_ms\"].to_numpy(dtype=\"float64\")\n",
    "\n",
    "    # Smooth speed\n",
    "    v_s = _moving_avg(v, roll_win)\n",
    "\n",
    "    # Detect peaks in smoothed speed\n",
    "    peaks = _find_speed_peaks(\n",
    "        v_s,\n",
    "        t_ms,\n",
    "        min_prominence=min_prom,\n",
    "        min_height=min_height,\n",
    "        min_peak_distance_ms=min_dist_ms,\n",
    "    )\n",
    "\n",
    "    submoves = int(peaks.size)\n",
    "    dur = float(t_ms[-1] - t_ms[0])\n",
    "    rate = submoves / (dur / 1000.0) if (np.isfinite(dur) and dur > 0) else np.nan\n",
    "\n",
    "    # Submovement deviation is only defined if we have at least one segment\n",
    "    # (i.e., at least 2 peaks)\n",
    "    if submoves >= 2:\n",
    "        devs = _compute_submovement_deviations(g, peaks)\n",
    "        mean_dev = np.nanmean(devs) if len(devs) else np.nan\n",
    "    else:\n",
    "        mean_dev = np.nan\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"submovements\": [submoves],\n",
    "            \"trial_duration_ms\": [dur],\n",
    "            \"submovements_per_s\": [rate],\n",
    "            \"mean_submovement_deviation\": [mean_dev],\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 3) Public API functions\n",
    "# =============================================================================\n",
    "\n",
    "def submovements_per_trial_speed_peaks(\n",
    "    df_mouse: pd.DataFrame,\n",
    "    group_cols\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute submovement metrics per trial (or per group-cols combination).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_mouse : pd.DataFrame\n",
    "        Full mouse trajectory data containing at least:\n",
    "        - 't_ms', 'x', 'y', and all columns listed in `group_cols`.\n",
    "    group_cols : sequence of str\n",
    "        Columns that define a group/trial, e.g. ('participant_id', 'trial_id').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        One row per group with columns:\n",
    "        - group_cols\n",
    "        - submovements\n",
    "        - trial_duration_ms\n",
    "        - submovements_per_s\n",
    "        - mean_submovement_deviation\n",
    "    \"\"\"\n",
    "    needed = set(group_cols) | {\"t_ms\", \"x\", \"y\"}\n",
    "    missing = [c for c in needed if c not in df_mouse.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"df_mouse is missing required columns: {missing}\")\n",
    "\n",
    "    # Group by the trial definition\n",
    "    gobj = df_mouse.groupby(list(group_cols), dropna=False)\n",
    "\n",
    "    # Apply per-group computation\n",
    "    out = gobj.apply(lambda g: _count_submovements_speed_peaks(g))\n",
    "\n",
    "    # Move group keys back into columns\n",
    "    out = out.reset_index()\n",
    "\n",
    "    # Clean up any potential 'level_*' columns introduced by groupby/apply\n",
    "    out = out.drop(\n",
    "        columns=[c for c in out.columns if c.startswith(\"level_\")],\n",
    "        errors=\"ignore\",\n",
    "    )\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def submovements_per_participant_speed_peaks(\n",
    "    df_mouse: pd.DataFrame,\n",
    "    group_cols\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute submovement metrics per group (per_trial) and aggregate to participant level.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - If group_cols = ('participant_id',), then each \"trial\" is effectively a\n",
    "      participant-level trajectory (no within-participant trial structure).\n",
    "    - If you include an additional trial column, e.g. ('participant_id', 'trial_id'),\n",
    "      then the per_trial DataFrame is truly per trial, and aggregation will\n",
    "      combine over all trials per participant.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_mouse : pd.DataFrame\n",
    "        Mouse trajectory data.\n",
    "    group_cols : sequence of str\n",
    "        Columns that define each trial group (must include participant_id).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    per_trial : pd.DataFrame\n",
    "        Output of submovements_per_trial_speed_peaks.\n",
    "    agg : pd.DataFrame\n",
    "        Participant-level summary with columns:\n",
    "        - participant_id (or first element of group_cols)\n",
    "        - total_submovements\n",
    "        - total_trial_time_ms\n",
    "        - mean_dev_over_trials\n",
    "        - submovements_per_s\n",
    "    \"\"\"\n",
    "    # First compute submovements per group/trial\n",
    "    per_trial = submovements_per_trial_speed_peaks(df_mouse, group_cols=group_cols)\n",
    "\n",
    "    # Identify participant column\n",
    "    part_col = \"participant_id\" if \"participant_id\" in group_cols else group_cols[0]\n",
    "\n",
    "    # Aggregate per participant\n",
    "    agg = (\n",
    "        per_trial.groupby(part_col, as_index=False)\n",
    "        .agg(\n",
    "            total_submovements=(\"submovements\", \"sum\"),\n",
    "            total_trial_time_ms=(\"trial_duration_ms\", \"sum\"),\n",
    "            mean_dev_over_trials=(\"mean_submovement_deviation\", \"mean\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Overall submovement rate per second, across all trials for each participant\n",
    "    agg[\"submovements_per_s\"] = agg[\"total_submovements\"] / (\n",
    "        agg[\"total_trial_time_ms\"] / 1000.0\n",
    "    )\n",
    "\n",
    "    return per_trial, agg\n",
    "\n",
    "\n",
    "per_trial, agg = submovements_per_participant_speed_peaks(df_mouse_with_steps, group_cols=GROUPING,)\n",
    "\n",
    "print(\"Per-trial (first 10 rows):\")\n",
    "print(per_trial.head(10))\n",
    "\n",
    "print(\"\\nPer-participant (first 10 rows):\")\n",
    "print(agg.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8723e8c0",
   "metadata": {},
   "source": [
    "# Submovement Deviation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
